\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[top=2.6cm, bottom=2.6cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{parskip}
\usepackage{lipsum} % Para texto de ejemplo
\usepackage{amsmath} % Para fórmulas matemáticas
\usepackage{algorithm} % Para escribir algoritmos
\usepackage{algpseudocode} % Para pseudocódigo

\title{Metaheurísticas: Práctica 1}
\author{Ángel Sánchez Guerrero}
\date{Marzo 2025}

\begin{document}
\thispagestyle{empty}

% Logo UGR arriba
\begin{center}
    \includegraphics[width=12cm]{logo_ugr.jpg}
\end{center}

\vspace{2cm}

% Título de asignatura
\begin{center}
    {\Huge \textbf{Metaheurísticas}} \\[3em]
    {\LARGE \textbf{Práctica Nº 1}} \\[1em]
    {\Large Problema de Mínima Dispersion Diferencial (MDDP)} \\[3em]

    {\large Curso Académico: \textbf{2024/2025}} \\[3em]

    {\large \textbf{Horario de prácticas:} Jueves 15:30 – 17:30} \\
    {\large \textbf{Email:} angel.sanchez01@correo.ugr.es} \\
    {\large \textbf{Nombre:} Ángel Sánchez Guerrero} \\
    {\large \textbf{DNI:} 12345678A} \\
\end{center}

\vfill

% Logo ETSIIT abajo
\begin{center}
    \includegraphics[width=4cm]{etsiit_logo.png}
\end{center}

\newpage
\tableofcontents
\newpage

\section{Descripción y formulación del problema}

El Problema de la Mínima Dispersión Diferencial (Minimum Differential Dispersion Problem, MDDP) es un problema de optimización combinatoria NP-completo. Su formulación es aparentemente sencilla, pero su resolución resulta computacionalmente compleja incluso para instancias de tamaño moderado, superando la hora de cómputo para casos de tamaño 50.

El problema consiste en seleccionar un subconjunto \(M\) de \(m\) elementos de un conjunto inicial \(S\) con \(n\) elementos (donde \(n > m\)), de forma que se minimice la dispersión entre los elementos escogidos. Para cada par de elementos, se conoce la distancia entre ellos, representada en una matriz \(D = (d_{ij})\) de dimensión \(n \times n\).

En el caso específico del MDDP, la medida de dispersión se calcula de la siguiente manera:
\begin{enumerate}
    \item Para cada elemento \(v\) seleccionado, se calcula su valor \(\Delta(v)\) como la suma de las distancias de este elemento al resto de elementos seleccionados.
    \item La dispersión de una solución, denotada como \(diff(S)\), se define como la diferencia entre los valores extremos de \(\Delta\):
    \[diff(S) = \max\{\Delta(v) : v \in S\} - \min\{\Delta(v) : v \in S\}\]
    \item El objetivo es minimizar esta medida de dispersión:
    \[\min diff(S)\]
\end{enumerate}

Formalmente, el problema se puede formular mediante la siguiente expresión:
\[\text{Minimizar } \max_{x_i \in M} \left( \sum_{j \in M} d_{ij} \right) - \min_{x_i \in M} \left( \sum_{j \in M} d_{ij} \right) \text{ con } M \subset S, |M| = m\]

Este problema tiene múltiples aplicaciones prácticas, como:
\begin{itemize}
    \item Ubicación óptima de instalaciones públicas (como farmacias, hospitales o estaciones de servicio)
    \item Selección de grupos homogéneos en entornos corporativos o educativos
    \item Identificación de redes densas en análisis de grafos
    \item Reparto equitativo de recursos
    \item Problemas de flujo en redes de transporte o comunicación
\end{itemize}

Debido a su complejidad computacional, resulta necesario emplear métodos aproximados para su resolución, como algoritmos voraces (greedy), búsqueda local o metaheurísticas más avanzadas, que permitan obtener soluciones de calidad en un tiempo razonable.

\section{Breve descripción de la aplicación de los algoritmos empleados al problema}

\subsection{Representación de soluciones}

La representación de soluciones utilizada en este trabajo es un vector de enteros que contiene los índices de los \(m\) elementos seleccionados del conjunto original de \(n\) elementos. En la implementación, esto se maneja como un objeto \texttt{tSolution}, que es simplemente un vector de enteros donde cada posición contiene el índice (entre 0 y n-1) de un elemento seleccionado.

Esta representación garantiza que:
\begin{itemize}
    \item Cada solución contiene exactamente \(m\) elementos
    \item No hay elementos repetidos
    \item El orden de los elementos no es relevante, aunque por simplicidad se mantienen ordenados
\end{itemize}

Por ejemplo, para un problema con \(n=100\) y \(m=10\), una solución válida podría ser el vector:
\[S = [3, 15, 24, 36, 42, 55, 67, 78, 83, 97]\]

\subsection{Cálculo de la función objetivo}

La función objetivo del MDDP evalúa la dispersión diferencial de una solución dada. Se implementa de la siguiente manera:

\begin{algorithm}
\caption{Cálculo de la dispersión diferencial}
\begin{algorithmic}[1]
\Function{fitness}{solucion}
    \State $sumas \gets$ vector de tamaño $m$ inicializado con ceros
    \For{$i \gets 0$ hasta $m-1$}
        \For{$j \gets 0$ hasta $m-1$}
            \If{$i \neq j$}
                \State $idx1 \gets$ solucion$[i]$
                \State $idx2 \gets$ solucion$[j]$
                \State $sumas[i] \gets sumas[i] + distancias[idx1][idx2]$
            \EndIf
        \EndFor
    \EndFor
    \State $maxSuma \gets$ máximo valor en $sumas$
    \State $minSuma \gets$ mínimo valor en $sumas$
    \State \Return $maxSuma - minSuma$
\EndFunction
\end{algorithmic}
\end{algorithm}

\newpage

\subsection{Factorización del cálculo de la función objetivo}

Para mejorar la eficiencia, se implementa una factorización que permite calcular el efecto de un cambio en la solución sin recalcular completamente la función objetivo. Esta factorización mantiene las sumas de distancias para cada elemento seleccionado y las actualiza cuando se realiza un movimiento:

\begin{algorithm}
\caption{Cálculo factorizado al reemplazar un elemento}
\begin{algorithmic}[1]
\Function{fitness\_factorizado}{solucion, info, pos\_cambio, nuevo\_valor}
    \State $viejo\_valor \gets$ solucion$[pos\_cambio]$
    \State $nueva\_suma \gets 0$
    \State $nuevas\_sumas \gets$ copia de $info.sumas$
    
    \For{$i \gets 0$ hasta $m-1$}
        \If{$i \neq pos\_cambio$}
            \State $idx \gets$ solucion$[i]$
            \State $nueva\_suma \gets nueva\_suma + distancias[nuevo\_valor][idx]$
            \State $nuevas\_sumas[i] \gets nuevas\_sumas[i] - distancias[viejo\_valor][idx] + distancias[nuevo\_valor][idx]$
        \EndIf
    \EndFor
    
    \State $nuevas\_sumas[pos\_cambio] \gets nueva\_suma$
    \State $max\_suma \gets$ máximo valor en $nuevas\_sumas$
    \State $min\_suma \gets$ mínimo valor en $nuevas\_sumas$
    \State \Return $max\_suma - min\_suma$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Operador de vecindad: Intercambio}

El operador de vecindad utilizado en la búsqueda local es el operador de intercambio (Int), que consiste en reemplazar un elemento seleccionado por otro no seleccionado. Este operador mantiene la cardinalidad de la solución constante y garantiza que todas las soluciones vecinas sean factibles.

\begin{algorithm}
\caption{Operador de intercambio}
\begin{algorithmic}[1]
\Function{Intercambio}{solucion, pos, nuevo\_valor}
    \State $nueva\_solucion \gets$ copia de $solucion$
    \State $nueva\_solucion[pos] \gets nuevo\_valor$
    \State \Return $nueva\_solucion$
\EndFunction
\end{algorithmic}
\end{algorithm}

\newpage

\subsection{Generación de soluciones aleatorias}

Para inicializar los algoritmos, se generan soluciones aleatorias válidas mediante el siguiente procedimiento:

\begin{algorithm}
\caption{Generación de solución aleatoria}
\begin{algorithmic}[1]
\Function{CrearSolucionAleatoria}{}
    \State $conjunto\_unico \gets$ conjunto vacío
    \While{tamaño de $conjunto\_unico < m$}
        \State $valor\_aleatorio \gets$ entero aleatorio entre $0$ y $n-1$
        \State Insertar $valor\_aleatorio$ en $conjunto\_unico$
    \EndWhile
    \State $solucion \gets$ convertir $conjunto\_unico$ a vector
    \State Ordenar $solucion$
    \State \Return $solucion$
\EndFunction
\end{algorithmic}
\end{algorithm}

Estas definiciones y operadores comunes serán utilizados por los distintos algoritmos implementados para resolver el problema MDDP, proporcionando una base unificada para su desarrollo y análisis.

\newpage

\section{Descripción en pseudocódigo de los algoritmos implementados}

En esta sección se presentan los pseudocódigos específicos de los algoritmos implementados para resolver el problema MDDP. Estos algoritmos utilizan los operadores y definiciones comunes presentados en la sección anterior.

\subsection{Algoritmo Aleatorio}

El algoritmo aleatorio es el más simple de los implementados. Consiste en generar múltiples soluciones aleatorias y quedarse con la mejor.

\begin{algorithm}
\caption{Algoritmo de Búsqueda Aleatoria}
\begin{algorithmic}[1]
\Function{OptimizarAleatorio}{problema, max\_evals}
    \State $mejor\_solucion \gets$ nulo
    \State $mejor\_fitness \gets$ $\infty$
    
    \For{$i \gets 1$ hasta $max\_evals$}
        \State $solucion \gets$ CrearSolucionAleatoria()
        \State $fitness \gets$ problema.fitness($solucion$)
        
        \If{$fitness < mejor\_fitness$}
            \State $mejor\_solucion \gets solucion$
            \State $mejor\_fitness \gets fitness$
        \EndIf
    \EndFor
    
    \State \Return $\{mejor\_solucion, mejor\_fitness\}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\newpage

\subsection{Algoritmo Greedy}

El algoritmo Greedy para el problema MDDP construye una solución progresivamente, comenzando con un elemento aleatorio y añadiendo en cada paso el elemento que minimice la dispersión de la solución parcial.

\begin{algorithm}
\caption{Algoritmo Greedy para el MDDP}
\begin{algorithmic}[1]
\Function{OptimizarGreedy}{problema, max\_evals}
    \State $n \gets$ problema.getN()
    \State $m \gets$ problema.getM()
    \State $evals \gets 0$
    
    \State // Inicializar conjuntos de elementos disponibles y seleccionados
    \State $disponibles \gets \{0, 1, 2, ..., n-1\}$ 
    \State $solucion \gets$ vector vacío
    
    \State // Seleccionar primer elemento aleatorio
    \State $primer\_elemento \gets$ elemento aleatorio de $disponibles$
    \State Añadir $primer\_elemento$ a $solucion$, eliminar de $disponibles$
    
    \While{tamaño de $solucion < m$ Y $evals < max\_evals$}
        \State $mejor\_dispersion \gets \infty$
        \State $mejor\_elemento \gets -1$
        
        \For{cada $candidato$ en $disponibles$}
            \State $solucion\_temp \gets solucion$ con $candidato$ añadido
            \State $dispersion \gets$ problema.fitness($solucion\_temp$)
            \State $evals \gets evals + 1$
            
            \If{$dispersion < mejor\_dispersion$}
                \State $mejor\_dispersion \gets dispersion$
                \State $mejor\_elemento \gets candidato$
            \EndIf
            
            \If{$evals \geq max\_evals$} \textbf{break} \EndIf
        \EndFor
        
        \If{$evals \geq max\_evals$} \textbf{break} \EndIf
        
        \State Añadir $mejor\_elemento$ a $solucion$
        \State Eliminar $mejor\_elemento$ de $disponibles$
    \EndWhile
    
    \State Ordenar $solucion$
    \State $fitness\_final \gets$ problema.fitness($solucion$)
    \State \Return $\{solucion, fitness\_final\}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\newpage

\subsection{Algoritmo de Búsqueda Local}

El algoritmo de Búsqueda Local implementado utiliza la estrategia del primer mejor (first improvement), explorando el vecindario según dos modos: aleatorio (randLS) o heurístico (heurLS). Este último prioriza los elementos seleccionados según su contribución al valor de dispersión.

\subsubsection{Inicialización y determinación del orden de exploración}

\begin{algorithm}
\caption{Algoritmo de Búsqueda Local del Primer Mejor - Parte 1}
\begin{algorithmic}[1]
\Function{OptimizarBL}{problema, max\_evals, modo\_exploracion}
    \State $n \gets$ problema.getN()
    \State $m \gets$ problema.getM()
    
    \State // Generar solución inicial aleatoria
    \State $solucion \gets$ CrearSolucionAleatoria()
    \State $fitness \gets$ problema.fitness($solucion$)
    \State $info \gets$ problema.generarInfoFactorizacion($solucion$)
    
    \State $evals \gets 1$ \Comment{Contabilizar evaluación inicial}
    \State $mejora \gets$ verdadero
    
    \State // Inicializar conjuntos de elementos seleccionados y no seleccionados
    \State $seleccionados \gets$ conjunto con elementos de $solucion$
    \State $no\_seleccionados \gets \{0, 1, ..., n-1\} - seleccionados$
    
    \While{$mejora$ Y $evals < max\_evals$}
        \State $mejora \gets$ falso
        
        \If{$modo\_exploracion = heurLS$}
            \State $contribuciones \gets$ vector vacío
            
            \For{$i \gets 0$ hasta $m-1$}
                \State $elem \gets solucion[i]$
                \State $fitness\_sin \gets$ problema.fitness\_factorizado($solucion, info, i, elem$)
                \State $contribucion \gets fitness\_sin - fitness$
                \State Añadir $(i, contribucion)$ a $contribuciones$
            \EndFor
            
            \State Ordenar $contribuciones$ por contribución (menor primero)
            \State $posiciones \gets$ extraer índices de posición de $contribuciones$
        \Else
            \State $posiciones \gets \{0, 1, ..., m-1\}$
            \State Barajar $posiciones$ aleatoriamente
        \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\newpage
\subsubsection{Exploración del vecindario y selección del primer mejor vecino}

\begin{algorithm}
\caption{Algoritmo de Búsqueda Local del Primer Mejor - Parte 2}
\begin{algorithmic}[1]
\Function{OptimizarBL}{problema, max\_evals, modo\_exploracion} \textbf{(continuación)}
    \While{$mejora$ Y $evals < max\_evals$}
    \State (...código anterior)
        \For{cada $pos$ en $posiciones$}
            \If{$mejora$ O $evals \geq max\_evals$} \textbf{break} \EndIf
            
            \State $elem\_actual \gets solucion[pos]$
            \State $candidatos \gets$ vector con elementos de $no\_seleccionados$
            \State Barajar $candidatos$ aleatoriamente
            
            \For{cada $candidato$ en $candidatos$}
                \If{$evals \geq max\_evals$} \textbf{break}\EndIf
                
                \State $nuevo\_fitness \gets$ problema.fitness\_factorizado($solucion, info, pos, candidato$)
                \State $evals \gets evals + 1$
                
                \If{$nuevo\_fitness < fitness$}
                    \State // Actualizar conjuntos
                    \State Eliminar $elem\_actual$ de $seleccionados$
                    \State Añadir $candidato$ a $seleccionados$
                    \State Eliminar $candidato$ de $no\_seleccionados$
                    \State Añadir $elem\_actual$ a $no\_seleccionados$
                    
                    \State // Actualizar información factorizada
                    \State problema.actualizarInfoFactorizacion($info, solucion, pos, candidato$)
                    
                    \State // Actualizar solución
                    \State $solucion[pos] \gets candidato$
                    \State $fitness \gets nuevo\_fitness$
                    
                    \State $mejora \gets$ verdadero
                    \State \textbf{break} \Comment{Primer mejor encontrado}
                \EndIf
            \EndFor
        \EndFor
    \EndWhile
    
    \State \Return $\{solucion, fitness\}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\newpage
\section{Estructura del código y manual de usuario}

El proyecto se ha implementado en C++ y estructurado de forma modular para facilitar su comprensión y mantenimiento. A continuación, se describe la organización del código y el proceso para compilarlo y ejecutarlo.

\subsection{Estructura de directorios}

\begin{itemize}
    \item \textbf{inc/}: Contiene los archivos de cabecera (.h) con las declaraciones de clases y funciones.
        \begin{itemize}
            \item \textbf{mddproblem.h}: Define la clase para el problema MDDP.
            \item \textbf{randomsearch.h}: Implementa el algoritmo aleatorio.
            \item \textbf{greedy.h}: Implementa el algoritmo Greedy.
            \item \textbf{localsearch.h}: Define la búsqueda local y sus variantes.
        \end{itemize}
    \item \textbf{src/}: Contiene los archivos de implementación (.cpp) de las clases y algoritmos.
    \item \textbf{datos\_MDD/}: Contiene los 50 ficheros de instancias del problema MDDP con diferentes valores de n y m.
    \item \textbf{build/}: Directorio generado tras la compilación donde se almacenan los ejecutables.
    \item \textbf{common/}: Incluye utilidades comunes para todos los algoritmos:
        \begin{itemize}
            \item \textbf{random.hpp}: Implementación del generador de números aleatorios.
            \item \textbf{problem.h}: Clase base abstracta para problemas de optimización.
            \item \textbf{solution.h}: Definición del tipo de solución.
            \item \textbf{mh.h}: Clase base para metaheurísticas.
        \end{itemize}
\end{itemize}

\subsection{Componentes principales}

El proyecto se organiza en las siguientes componentes clave:

\begin{itemize}
    \item \textbf{Representación del Problema}:
        \begin{itemize}
            \item \textbf{mddproblem.h/cpp}: Implementa la clase MDDProblem que encapsula la lógica del problema, incluyendo la carga de instancias desde archivos, el cálculo de la función objetivo y los mecanismos de factorización para optimizar la evaluación de soluciones vecinas.
        \end{itemize}
    
    \item \textbf{Algoritmos de resolución}:
        \begin{itemize}
            \item \textbf{randomsearch.h/cpp}: Implementa la búsqueda aleatoria que genera soluciones aleatorias hasta agotar el número de evaluaciones.
            \item \textbf{greedy.h/cpp}: Implementa el algoritmo constructivo Greedy que añade elementos uno a uno seleccionando el mejor candidato en cada paso.
            \item \textbf{localsearch.h/cpp}: Implementa el algoritmo de búsqueda local con dos modos de exploración del vecindario: aleatorio (randLS) y heurístico (heurLS).
        \end{itemize}
        
    \item \textbf{Programas ejecutables}:
        \begin{itemize}
            \item \textbf{test\_random.cpp}: Programa para probar específicamente el algoritmo aleatorio.
            \item \textbf{test\_greedy.cpp}: Programa para probar específicamente el algoritmo Greedy.
            \item \textbf{test\_localsearch.cpp}: Programa para probar específicamente el algoritmo de búsqueda local.
            \item \textbf{test\_all.cpp}: Programa para probar todos los algoritmos sobre una instancia.
            \item \textbf{run\_experiments.cpp}: Programa principal que ejecuta todos los experimentos sobre las 50 instancias del problema, calculando estadísticas y guardando resultados en archivos CSV.
        \end{itemize}
\end{itemize}

\subsection{Compilación del proyecto}

El proyecto utiliza CMake como sistema de construcción, lo que facilita su compilación en diferentes plataformas. Para compilar el proyecto, se deben seguir estos pasos:

\begin{enumerate}
    \item Asegurarse de tener instalado CMake (versión 3.31 o superior) y un compilador de C++ compatible con C++14.
    \item Abrir una terminal en el directorio raíz del proyecto.
    \item Crear y acceder al directorio de compilación:
    \begin{verbatim}
    mkdir -p build
    cd build
    \end{verbatim}
    \item Generar los archivos de compilación:
    \begin{verbatim}
    cmake ..
    \end{verbatim}
    \item Compilar el proyecto:
    \begin{verbatim}
    make
    \end{verbatim}
\end{enumerate}

Este proceso generará varios ejecutables en el directorio \texttt{build/}, incluyendo \texttt{main}, \texttt{test\_random}, \texttt{test\_greedy}, \texttt{test\_localsearch}, \texttt{test\_all} y \texttt{run\_experiments}.

\subsection{Ejecución de los programas}

Una vez compilado el proyecto, se pueden ejecutar los siguientes programas:

\begin{itemize}
    \item \textbf{test\_random}: Ejecuta el algoritmo aleatorio sobre una instancia específica.
    \begin{verbatim}
    ./test_random <archivo_instancia> [semilla]
    \end{verbatim}
    
    \item \textbf{test\_greedy}: Ejecuta el algoritmo Greedy sobre una instancia específica.
    \begin{verbatim}
    ./test_greedy <archivo_instancia> [semilla]
    \end{verbatim}
    
    \item \textbf{test\_localsearch}: Ejecuta ambas versiones del algoritmo de búsqueda local (randLS y heurLS) sobre una instancia y compara sus resultados.
    \begin{verbatim}
    ./test_localsearch <archivo_instancia> [semilla]
    \end{verbatim}
    
    \item \textbf{test\_all}: Ejecuta todos los algoritmos sobre una instancia específica para comparar resultados.
    \begin{verbatim}
    ./test_all <archivo_instancia> [semilla]
    \end{verbatim}
    
    \item \textbf{run\_experiments}: Ejecuta todos los experimentos sobre el conjunto completo de instancias y genera archivos CSV con los resultados.
    \begin{verbatim}
    ./run_experiments <directorio_instancias>
    \end{verbatim}
    Este programa utiliza automáticamente las 5 semillas predefinidas (1234, 5678, 9012, 3456, 7890) y genera cuatro archivos de resultados:
    \begin{itemize}
        \item \texttt{results\_detailed.csv}: Resultados detallados de cada ejecución.
        \item \texttt{results\_by\_case.csv}: Resultados promediados por caso.
        \item \texttt{results\_by\_size.csv}: Resultados agrupados por tamaño de instancia.
        \item \texttt{results\_global.csv}: Resultados globales por algoritmo.
    \end{itemize}
\end{itemize}

En todos los programas, si no se especifica una semilla, se utiliza el valor por defecto 42.

\subsection{Ejemplo de ejecución}

A continuación, se muestra un ejemplo real de ejecución del algoritmo de búsqueda local para la instancia GKD-b\_10\_n25\_m7:

\begin{verbatim}
$ ./build/test_localsearch datos_MDD/GKD-b_10_n25_m7.txt 222
Ejecutando búsqueda local con exploración ALEATORIA (randLS)...
Fitness (randLS): 47.9688
Evaluaciones: 208
Tiempo de ejecución: 0.000267862 segundos
Elementos seleccionados: 19 12 16 17 5 6 2 

Ejecutando búsqueda local con exploración HEURÍSTICA (heurLS)...
Fitness (heurLS): 39.0557
Evaluaciones: 181
Tiempo de ejecución: 0.000349462 segundos
Elementos seleccionados: 5 1 16 17 9 6 12 
\end{verbatim}

Para ejecutar todos los algoritmos sobre una misma instancia y compararlos:

\begin{verbatim}
$ ./test_all ../datos_MDD/GKD-b_10_n25_m7.txt 222
\end{verbatim}

Para ejecutar todos los experimentos y generar las tablas estadísticas:

\begin{verbatim}
$ ./run_experiments ../datos_MDD/
\end{verbatim}

El programa procesará las 50 instancias con todos los algoritmos y generará los archivos CSV con los resultados. Durante la ejecución, mostrará información sobre el progreso y los resultados intermedios. Una vez finalizado, los archivos CSV pueden importarse a herramientas como Excel o R para generar gráficos y realizar análisis adicionales.

\section{Resultados experimentales}

En esta sección se presentan los resultados obtenidos de la ejecución de los algoritmos implementados sobre los 50 casos del problema MDDP. Se muestran tres tablas correspondientes a cada uno de los algoritmos: Greedy, Búsqueda Local con exploración aleatoria (LSrandom) y Búsqueda Local con exploración heurística (LSheur).

\subsection{Configuración experimental}

Para garantizar la reproducibilidad de los resultados y seguir las indicaciones del guión de prácticas, se ha utilizado la siguiente configuración experimental:

\begin{itemize}
    \item \textbf{Semillas utilizadas}: Se han utilizado las siguientes semillas para el generador de números aleatorios:
    \begin{itemize}
        \item Semilla 1: 1234
        \item Semilla 2: 5678
        \item Semilla 3: 9012
        \item Semilla 4: 3456
        \item Semilla 5: 7890
    \end{itemize}
    
    Estas semillas se utilizan de manera diferente según el algoritmo:
    \begin{itemize}
        \item \textbf{RandomSearch}: Utiliza únicamente la primera semilla (1234).
        \item \textbf{GreedySearch}: También utiliza solo la primera semilla (1234).
        \item \textbf{Búsqueda Local (RandLS y HeurLS)}: Utilizan las 5 semillas diferentes para realizar 5 ejecuciones independientes por cada instancia.
    \end{itemize}
    
    \item \textbf{Número máximo de evaluaciones}: Para los algoritmos de búsqueda local y aleatorio, se estableció un límite de 100000 evaluaciones de la función objetivo. El algoritmo Greedy no requiere este parámetro, pues realiza un número fijo de evaluaciones determinado por la instancia.
    
    \item \textbf{Criterio de parada}: Además del límite de evaluaciones, los algoritmos de búsqueda local se detienen cuando no encuentran mejora en todo el vecindario explorado.
    
    \item \textbf{Medición de tiempos}: Para medir los tiempos de ejecución se utilizó el cronómetro de alta resolución proporcionado por la biblioteca \texttt{<chrono>} de C++.
\end{itemize}

\subsection{Resultados por algoritmo}

\subsubsection{Resultados obtenidos por el Algoritmo Greedy en el MDD}

\begin{table}[ht]
\centering
\footnotesize
\begin{tabular}{|l|r|r|}
\hline
\textbf{Caso} & \textbf{Desv} & \textbf{Tiempo} \\ \hline
GKD-b\_1\_n25\_m2 & 0 & 4.61e-05 \\ \hline
GKD-b\_2\_n25\_m2 & 0 & 4.74e-05 \\ \hline
GKD-b\_3\_n25\_m2 & 0 & 4.52e-05 \\ \hline
GKD-b\_4\_n25\_m2 & 0 & 5.92e-05 \\ \hline
GKD-b\_5\_n25\_m2 & 0 & 4.60e-05 \\ \hline
GKD-b\_6\_n25\_m7 & 426.36 & 0.00024 \\ \hline
GKD-b\_7\_n25\_m7 & 189.66 & 0.00021 \\ \hline
GKD-b\_8\_n25\_m7 & 264.56 & 0.00021 \\ \hline
GKD-b\_9\_n25\_m7 & 320.03 & 0.00023 \\ \hline
GKD-b\_10\_n25\_m7 & 359.59 & 0.00024 \\ \hline
GKD-b\_11\_n50\_m5 & 1994.96 & 0.00026 \\ \hline
GKD-b\_12\_n50\_m5 & 968.95 & 0.00025 \\ \hline
GKD-b\_13\_n50\_m5 & 830.04 & 0.00024 \\ \hline
GKD-b\_14\_n50\_m5 & 1510.09 & 0.00023 \\ \hline
GKD-b\_15\_n50\_m5 & 1824.35 & 0.00025 \\ \hline
GKD-b\_16\_n50\_m15 & 218.42 & 0.00180 \\ \hline
GKD-b\_17\_n50\_m15 & 129.10 & 0.00188 \\ \hline
GKD-b\_18\_n50\_m15 & 311.69 & 0.00185 \\ \hline
GKD-b\_19\_n50\_m15 & 240.68 & 0.00180 \\ \hline
GKD-b\_20\_n50\_m15 & 205.69 & 0.00181 \\ \hline
GKD-b\_21\_n100\_m10 & 570.81 & 0.00171 \\ \hline
GKD-b\_22\_n100\_m10 & 365.80 & 0.00171 \\ \hline
GKD-b\_23\_n100\_m10 & 248.50 & 0.00179 \\ \hline
GKD-b\_24\_n100\_m10 & 751.02 & 0.00176 \\ \hline
GKD-b\_25\_n100\_m10 & 235.35 & 0.00162 \\ \hline
GKD-b\_26\_n100\_m30 & 172.64 & 0.02036 \\ \hline
GKD-b\_27\_n100\_m30 & 330.81 & 0.01952 \\ \hline
GKD-b\_28\_n100\_m30 & 511.34 & 0.02000 \\ \hline
GKD-b\_29\_n100\_m30 & 177.00 & 0.01959 \\ \hline
GKD-b\_30\_n100\_m30 & 208.07 & 0.01999 \\ \hline
GKD-b\_31\_n125\_m12 & 493.18 & 0.00313 \\ \hline
GKD-b\_32\_n125\_m12 & 331.89 & 0.00290 \\ \hline
GKD-b\_33\_n125\_m12 & 426.97 & 0.00298 \\ \hline
GKD-b\_34\_n125\_m12 & 285.51 & 0.00324 \\ \hline
GKD-b\_35\_n125\_m12 & 311.10 & 0.00294 \\ \hline
GKD-b\_36\_n125\_m37 & 203.14 & 0.04308 \\ \hline
GKD-b\_37\_n125\_m37 & 73.80 & 0.04268 \\ \hline
GKD-b\_38\_n125\_m37 & 218.00 & 0.04352 \\ \hline
GKD-b\_39\_n125\_m37 & 184.82 & 0.04360 \\ \hline
GKD-b\_40\_n125\_m37 & 118.78 & 0.04264 \\ \hline
GKD-b\_41\_n150\_m15 & 220.59 & 0.00589 \\ \hline
GKD-b\_42\_n150\_m15 & 304.22 & 0.00610 \\ \hline
GKD-b\_43\_n150\_m15 & 597.36 & 0.00621 \\ \hline
GKD-b\_44\_n150\_m15 & 249.94 & 0.00619 \\ \hline
GKD-b\_45\_n150\_m15 & 239.29 & 0.00570 \\ \hline
GKD-b\_46\_n150\_m45 & 138.46 & 0.08884 \\ \hline
GKD-b\_47\_n150\_m45 & 117.80 & 0.09024 \\ \hline
GKD-b\_48\_n150\_m45 & 154.71 & 0.08983 \\ \hline
GKD-b\_49\_n150\_m45 & 206.10 & 0.08991 \\ \hline
GKD-b\_50\_n150\_m45 & 103.72 & 0.08941 \\ \hline
\end{tabular}
\end{table}

\newpage
\subsubsection{Resultados obtenidos por el Algoritmo LSrandom en el MDD}

\begin{table}[ht]
\centering
\footnotesize
\begin{tabular}{|l|r|r|}
\hline
\textbf{Caso} & \textbf{Desv} & \textbf{Tiempo} \\ \hline
GKD-b\_1\_n25\_m2 & 0 & 5.07e-05 \\ \hline
GKD-b\_2\_n25\_m2 & 0 & 5.03e-05 \\ \hline
GKD-b\_3\_n25\_m2 & 0 & 6.36e-05 \\ \hline
GKD-b\_4\_n25\_m2 & 0 & 5.10e-05 \\ \hline
GKD-b\_5\_n25\_m2 & 0 & 5.33e-05 \\ \hline
GKD-b\_6\_n25\_m7 & 141.82 & 0.00042 \\ \hline
GKD-b\_7\_n25\_m7 & 120.75 & 0.00040 \\ \hline
GKD-b\_8\_n25\_m7 & 93.80 & 0.00042 \\ \hline
GKD-b\_9\_n25\_m7 & 136.75 & 0.00036 \\ \hline
GKD-b\_10\_n25\_m7 & 63.26 & 0.00050 \\ \hline
GKD-b\_11\_n50\_m5 & 425.40 & 0.00056 \\ \hline
GKD-b\_12\_n50\_m5 & 646.43 & 0.00038 \\ \hline
GKD-b\_13\_n50\_m5 & 331.75 & 0.00055 \\ \hline
GKD-b\_14\_n50\_m5 & 724.04 & 0.00045 \\ \hline
GKD-b\_15\_n50\_m5 & 544.16 & 0.00037 \\ \hline
GKD-b\_16\_n50\_m15 & 219.92 & 0.00331 \\ \hline
GKD-b\_17\_n50\_m15 & 88.74 & 0.00357 \\ \hline
GKD-b\_18\_n50\_m15 & 184.99 & 0.00250 \\ \hline
GKD-b\_19\_n50\_m15 & 165.19 & 0.00287 \\ \hline
GKD-b\_20\_n50\_m15 & 205.46 & 0.00236 \\ \hline
GKD-b\_21\_n100\_m10 & 216.77 & 0.00318 \\ \hline
GKD-b\_22\_n100\_m10 & 251.99 & 0.00287 \\ \hline
GKD-b\_23\_n100\_m10 & 240.08 & 0.00245 \\ \hline
GKD-b\_24\_n100\_m10 & 298.63 & 0.00258 \\ \hline
GKD-b\_25\_n100\_m10 & 140.58 & 0.00384 \\ \hline
GKD-b\_26\_n100\_m30 & 126.86 & 0.02488 \\ \hline
GKD-b\_27\_n100\_m30 & 170.95 & 0.02750 \\ \hline
GKD-b\_28\_n100\_m30 & 155.70 & 0.02900 \\ \hline
GKD-b\_29\_n100\_m30 & 133.89 & 0.02703 \\ \hline
GKD-b\_30\_n100\_m30 & 159.32 & 0.02426 \\ \hline
GKD-b\_31\_n125\_m12 & 357.26 & 0.00985 \\ \hline
GKD-b\_32\_n125\_m12 & 131.56 & 0.00576 \\ \hline
GKD-b\_33\_n125\_m12 & 165.04 & 0.00779 \\ \hline
GKD-b\_34\_n125\_m12 & 151.84 & 0.00672 \\ \hline
GKD-b\_35\_n125\_m12 & 187.45 & 0.00513 \\ \hline
GKD-b\_36\_n125\_m37 & 144.26 & 0.07322 \\ \hline
GKD-b\_37\_n125\_m37 & 134.53 & 0.04911 \\ \hline
GKD-b\_38\_n125\_m37 & 191.68 & 0.04675 \\ \hline
GKD-b\_39\_n125\_m37 & 113.25 & 0.05203 \\ \hline
GKD-b\_40\_n125\_m37 & 134.20 & 0.06460 \\ \hline
GKD-b\_41\_n150\_m15 & 172.60 & 0.01295 \\ \hline
GKD-b\_42\_n150\_m15 & 169.60 & 0.01040 \\ \hline
GKD-b\_43\_n150\_m15 & 206.97 & 0.01392 \\ \hline
GKD-b\_44\_n150\_m15 & 162.69 & 0.01150 \\ \hline
GKD-b\_45\_n150\_m15 & 128.39 & 0.00935 \\ \hline
GKD-b\_46\_n150\_m45 & 155.02 & 0.09665 \\ \hline
GKD-b\_47\_n150\_m45 & 96.11 & 0.10936 \\ \hline
GKD-b\_48\_n150\_m45 & 82.88 & 0.14974 \\ \hline
GKD-b\_49\_n150\_m45 & 125.81 & 0.14308 \\ \hline
GKD-b\_50\_n150\_m45 & 111.18 & 0.12805 \\ \hline
\end{tabular}
\end{table}

\newpage
\subsubsection{Resultados obtenidos por el Algoritmo LSheur en el MDD}

\begin{table}[ht]
\centering
\footnotesize
\begin{tabular}{|l|r|r|}
\hline
\textbf{Caso} & \textbf{Desv} & \textbf{Tiempo} \\ \hline
GKD-b\_1\_n25\_m2 & 0 & 5.79e-05 \\ \hline
GKD-b\_2\_n25\_m2 & 0 & 5.09e-05 \\ \hline
GKD-b\_3\_n25\_m2 & 0 & 5.31e-05 \\ \hline
GKD-b\_4\_n25\_m2 & 0 & 5.02e-05 \\ \hline
GKD-b\_5\_n25\_m2 & 0 & 5.04e-05 \\ \hline
GKD-b\_6\_n25\_m7 & 188.57 & 0.00040 \\ \hline
GKD-b\_7\_n25\_m7 & 126.04 & 0.00039 \\ \hline
GKD-b\_8\_n25\_m7 & 115.65 & 0.00060 \\ \hline
GKD-b\_9\_n25\_m7 & 84.74 & 0.00075 \\ \hline
GKD-b\_10\_n25\_m7 & 73.24 & 0.00053 \\ \hline
GKD-b\_11\_n50\_m5 & 763.73 & 0.00053 \\ \hline
GKD-b\_12\_n50\_m5 & 720.06 & 0.00057 \\ \hline
GKD-b\_13\_n50\_m5 & 571.87 & 0.00050 \\ \hline
GKD-b\_14\_n50\_m5 & 811.18 & 0.00049 \\ \hline
GKD-b\_15\_n50\_m5 & 448.24 & 0.00041 \\ \hline
GKD-b\_16\_n50\_m15 & 219.09 & 0.00597 \\ \hline
GKD-b\_17\_n50\_m15 & 73.30 & 0.00687 \\ \hline
GKD-b\_18\_n50\_m15 & 97.63 & 0.00885 \\ \hline
GKD-b\_19\_n50\_m15 & 134.20 & 0.00502 \\ \hline
GKD-b\_20\_n50\_m15 & 109.43 & 0.00588 \\ \hline
GKD-b\_21\_n100\_m10 & 314.98 & 0.00476 \\ \hline
GKD-b\_22\_n100\_m10 & 355.05 & 0.00373 \\ \hline
GKD-b\_23\_n100\_m10 & 161.09 & 0.00462 \\ \hline
GKD-b\_24\_n100\_m10 & 365.08 & 0.00376 \\ \hline
GKD-b\_25\_n100\_m10 & 143.21 & 0.00461 \\ \hline
GKD-b\_26\_n100\_m30 & 125.36 & 0.07678 \\ \hline
GKD-b\_27\_n100\_m30 & 171.03 & 0.07891 \\ \hline
GKD-b\_28\_n100\_m30 & 216.22 & 0.07632 \\ \hline
GKD-b\_29\_n100\_m30 & 96.56 & 0.07088 \\ \hline
GKD-b\_30\_n100\_m30 & 165.44 & 0.06138 \\ \hline
GKD-b\_31\_n125\_m12 & 233.92 & 0.01491 \\ \hline
GKD-b\_32\_n125\_m12 & 180.52 & 0.00822 \\ \hline
GKD-b\_33\_n125\_m12 & 136.49 & 0.00879 \\ \hline
GKD-b\_34\_n125\_m12 & 160.29 & 0.01023 \\ \hline
GKD-b\_35\_n125\_m12 & 186.36 & 0.01346 \\ \hline
GKD-b\_36\_n125\_m37 & 113.03 & 0.13308 \\ \hline
GKD-b\_37\_n125\_m37 & 139.07 & 0.15237 \\ \hline
GKD-b\_38\_n125\_m37 & 140.14 & 0.15692 \\ \hline
GKD-b\_39\_n125\_m37 & 145.15 & 0.10897 \\ \hline
GKD-b\_40\_n125\_m37 & 156.33 & 0.10222 \\ \hline
GKD-b\_41\_n150\_m15 & 185.57 & 0.02087 \\ \hline
GKD-b\_42\_n150\_m15 & 250.30 & 0.02327 \\ \hline
GKD-b\_43\_n150\_m15 & 165.72 & 0.01309 \\ \hline
GKD-b\_44\_n150\_m15 & 235.03 & 0.02065 \\ \hline
GKD-b\_45\_n150\_m15 & 153.46 & 0.01660 \\ \hline
GKD-b\_46\_n150\_m45 & 121.80 & 0.23819 \\ \hline
GKD-b\_47\_n150\_m45 & 85.96 & 0.25197 \\ \hline
GKD-b\_48\_n150\_m45 & 104.22 & 0.28723 \\ \hline
GKD-b\_49\_n150\_m45 & 128.89 & 0.25813 \\ \hline
GKD-b\_50\_n150\_m45 & 151.46 & 0.24663 \\ \hline
\end{tabular}
\end{table}

\newpage
\subsection{Resultados globales}

Una vez analizados los resultados detallados por algoritmo y caso, en esta sección presentamos las tablas resumen que agrupan los datos por tamaño y los resultados globales.

\subsubsection{Resultados globales por Tamaño en el MDD}

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|r|r|}
\hline
\textbf{Algoritmo} & \textbf{Tamaño} & \textbf{Desv} & \textbf{Tiempo} \\ \hline
Greedy & 25 & 156.02 & 0.00014 \\ \hline
LSrandom & 25 & 55.64 & 0.00024 \\ \hline
LSheur & 25 & 58.83 & 0.00029 \\ \hline
Greedy & 50 & 823.40 & 0.00104 \\ \hline
LSrandom & 50 & 353.61 & 0.00169 \\ \hline
LSheur & 50 & 394.87 & 0.00351 \\ \hline
Greedy & 100 & 357.14 & 0.01081 \\ \hline
LSrandom & 100 & 189.47 & 0.01476 \\ \hline
LSheur & 100 & 211.40 & 0.03858 \\ \hline
Greedy & 125 & 264.72 & 0.02307 \\ \hline
LSrandom & 125 & 171.11 & 0.03210 \\ \hline
LSheur & 125 & 159.13 & 0.07092 \\ \hline
Greedy & 150 & 233.22 & 0.04783 \\ \hline
LSrandom & 150 & 141.12 & 0.06850 \\ \hline
LSheur & 150 & 158.24 & 0.13766 \\ \hline
\end{tabular}
\end{table}

\subsubsection{Resultados globales totales en el MDD}

\begin{table}[ht]
\centering
\begin{tabular}{|l|r|r|}
\hline
\textbf{Algoritmo} & \textbf{Desv} & \textbf{Tiempo} \\ \hline
Greedy & 366.90 & 0.01658 \\ \hline
LSrandom & 182.19 & 0.02346 \\ \hline
LSheur & 196.49 & 0.05019 \\ \hline
\end{tabular}
\end{table}

\newpage
\section{Análisis de resultados}

A continuación se presenta un análisis detallado de los resultados obtenidos con los algoritmos implementados para resolver el problema MDDP. Este análisis se centra en interpretar el comportamiento de cada algoritmo y las relaciones entre su diseño y los resultados experimentales.

\subsection{Análisis comparativo global}

Observando las tablas de resultados globales, podemos extraer varias conclusiones importantes:

\begin{itemize}
    \item El algoritmo Greedy, aunque es el más rápido (0.01658 segundos en promedio), presenta la mayor desviación respecto a los mejores valores conocidos (366.90\%). Esto es consistente con la naturaleza miope de este algoritmo, que toma decisiones localmente óptimas sin considerar su impacto en la solución final.
    
    \item La Búsqueda Local con exploración aleatoria (LSrandom) logra la menor desviación global (182.19\%), con un tiempo computacional moderado (0.02346 segundos). Esto muestra la efectividad de esta metaheurística para escapar de óptimos locales y explorar más ampliamente el espacio de soluciones.
    
    \item La Búsqueda Local con exploración heurística (LSheur) obtiene resultados intermedios en calidad (196.49\% de desviación), pero con el mayor coste computacional (0.05019 segundos). Contrario a lo esperado, la versión heurística no supera a la versión aleatoria en términos de calidad global de soluciones.
\end{itemize}

Este comportamiento podría explicarse por la posible tendencia de la exploración heurística a quedar atrapada en regiones del espacio de búsqueda que, aunque prometedoras inicialmente, no contienen las mejores soluciones globales.

\subsection{Análisis por tamaño de instancia}

Analizando el comportamiento de los algoritmos según el tamaño de las instancias:

\begin{itemize}
    \item \textbf{Instancias pequeñas (n=25)}: Todos los algoritmos obtienen resultados relativamente buenos, con desviaciones moderadas. Las búsquedas locales (55.64\% y 58.83\%) superan claramente al Greedy (156.02\%), sin una diferencia sustancial entre las dos versiones de BL.
    
    \item \textbf{Instancias medianas (n=50)}: Se observa una degradación significativa del algoritmo Greedy (823.40\%), mientras que las búsquedas locales mantienen un rendimiento más estable (353.61\% y 394.87\%).
    
    \item \textbf{Instancias grandes (n=100-150)}: El rendimiento de todos los algoritmos mejora respecto a las instancias medianas, con desviaciones más controladas. Especialmente destacable es que la diferencia entre Greedy y las búsquedas locales se reduce (233.22\% vs. 141.12\% y 158.24\% para n=150).
\end{itemize}

Esta evolución sugiere que la estructura del problema varía con el tamaño. Particularmente interesante es la mejora relativa del Greedy en instancias grandes, lo que podría indicar que en estas instancias, las decisiones localmente óptimas tienden a producir soluciones globalmente aceptables.

\subsection{Análisis del comportamiento de los algoritmos}

\subsubsection{Algoritmo Greedy}

El algoritmo Greedy muestra una alta variabilidad en su rendimiento:

\begin{itemize}
    \item Excelente en instancias muy pequeñas (n=25, m=2), donde obtiene la solución óptima (desviación 0\%).
    \item Muy deficiente en instancias medianas, especialmente con n=50, m=5, donde alcanza desviaciones superiores al 1500\%.
    \item Mejora considerablemente en instancias grandes con valores de m proporcionalmente altos (n=150, m=45), con desviaciones en torno al 100-200\%.
\end{itemize}

Este comportamiento puede explicarse por la naturaleza combinatoria del problema. En instancias muy pequeñas, el espacio de soluciones es reducido y el algoritmo tiene alta probabilidad de encontrar buenas soluciones. En instancias medianas, la complejidad aumenta rápidamente, pero el algoritmo solo explora un camino. En instancias grandes con m grande, es posible que la distribución de los elementos haga que muchos caminos de construcción lleven a soluciones relativamente buenas.

\subsubsection{Búsqueda Local con exploración aleatoria (LSrandom)}

Este algoritmo muestra un comportamiento más consistente a través de diferentes tamaños:

\begin{itemize}
    \item Al igual que Greedy, obtiene soluciones óptimas para instancias muy pequeñas.
    \item Mantiene desviaciones más controladas en instancias medianas (353.61\% para n=50).
    \item Consigue las mejores soluciones globales, especialmente efectivas en instancias grandes.
\end{itemize}

La capacidad de la búsqueda local para mejorar iterativamente una solución inicial permite superar las limitaciones del enfoque Greedy. La exploración aleatoria del vecindario facilita escapar de óptimos locales, lo que explica su mejor rendimiento global.

\subsubsection{Búsqueda Local con exploración heurística (LSheur)}

Este algoritmo presenta un comportamiento interesante:

\begin{itemize}
    \item Similar a LSrandom en instancias pequeñas.
    \item Ligeramente peor que LSrandom en instancias medianas.
    \item Más efectivo que LSrandom en algunas instancias grandes (especialmente n=125).
    \item Significativamente más lento que LSrandom en todas las categorías, con tiempos hasta 2-3 veces mayores.
\end{itemize}

La estrategia heurística para explorar el vecindario parece enfocar la búsqueda demasiado intensamente en ciertas regiones, lo que puede resultar contraproducente si esas regiones no contienen las mejores soluciones. El mayor coste computacional refleja el esfuerzo adicional para ordenar los elementos según su contribución al fitness.

\subsection{Relación entre tiempo y calidad}

Existe un claro compromiso entre tiempo de ejecución y calidad de las soluciones:

\begin{itemize}
    \item El algoritmo Greedy es aproximadamente 1.4 veces más rápido que LSrandom, pero obtiene soluciones con una desviación 2 veces mayor.
    \item LSheur es 2.1 veces más lento que LSrandom, pero no mejora la calidad de las soluciones en promedio.
\end{itemize}

Estos datos sugieren que LSrandom representa el mejor equilibrio entre calidad y tiempo de ejecución para este problema.

\subsection{Conclusiones}

Del análisis realizado se pueden extraer las siguientes conclusiones:

\begin{enumerate}
    \item La Búsqueda Local con exploración aleatoria (LSrandom) es la mejor opción global para resolver el problema MDDP, ofreciendo un buen equilibrio entre calidad de soluciones y tiempo de ejecución.
    
    \item El algoritmo Greedy puede ser una alternativa aceptable cuando el tiempo de ejecución es crítico o para instancias muy grandes con valores de m elevados.
    
    \item La estrategia de exploración heurística (LSheur) no justifica su mayor coste computacional, ya que no mejora significativamente los resultados de la exploración aleatoria.
    
    \item La dificultad del problema no escala linealmente con el tamaño de la instancia, siendo las instancias de tamaño medio (n=50) aparentemente más difíciles que algunas instancias grandes.
    
    \item La factorización de la función objetivo ha sido crucial para la eficiencia de los algoritmos de búsqueda local, permitiendo evaluar movimientos con un coste computacional reducido.
\end{enumerate}

Estos resultados demuestran la efectividad de las técnicas de búsqueda local para problemas de optimización combinatoria como el MDDP, y proporcionan una base sólida para futuras investigaciones con metaheurísticas más avanzadas.

\end{document}
